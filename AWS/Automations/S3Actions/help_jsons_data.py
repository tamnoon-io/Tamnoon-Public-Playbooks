# Do not edit this file directly. To make changes, update the associated json files that are located in S3Actions.

s3_deny_http_access_readme_data= {'help': 'This automation helps to execute Tamnoon S3 soft configuration automation to add deny policy for HTTP access.', 'cli_args': {'profile': 'Use the aws profile for setting up session during automation.', 'awsAccessKey': 'Use the aws access key for setting up session during automation. This must be accompanied by --awsSecret.', 'awsSecret': 'Use the aws secret key for setting up session during automation. This must be accompanied by --awsAccessKey.', 'awsSessionToken': 'Use the short term session token for setting up session during automation. This must be accompanied by --awsSecret and --awsAccessKey.', 'bucketNames': 'Comma separated list of S3 Buckets Name', 'regions': "List of Regions. If not given then default value is 'all', i.e., remedy will configure all the S3 Buckets without checking its regions.", 'file': 'The path to a yml/json file that contain all the script input parameters.', 'outputType': 'The type of output of script execution. available options are json (default) and csv.', 'outDir': 'The path to store output of script execution. The default is the current working directory.', 'logLevel': 'Used to categorize and prioritize log levels based on severity or importance. Its values can be INFO, DEBUG, WARNING, ERROR, or CRITICAL. The default value is INFO.', 'testId': 'Description for test to be executed.'}}

s3_enable_mfa_protection_readme_data= {'help': 'This automation helps to to execute Tamnoon S3 soft configuration automation to enable bucket mfa delete protection.', 'cli_args': {'profile': 'Use the aws profile for setting up session during automation.', 'awsAccessKey': 'Use the aws access key for setting up session during automation. This must be accompanied by --awsSecret.', 'awsSecret': 'Use the aws secret key for setting up session during automation. This must be accompanied by --awsAccessKey.', 'awsSessionToken': 'Use the short term session token for setting up session during automation. This must be accompanied by --awsSecret and --awsAccessKey.', 'bucketNames': 'Comma separated list of S3 Buckets Name', 'regions': "List of Regions. If not given then default value is 'all', i.e., remedy will configure all the S3 Buckets without checking its regions.", 'actionParams': '1. mfa - The concatenation of the authentication devices serial number, a space, and the value that is displayed on your authentication device.', 'revert': 'Boolean Value true/false used to revert the action.', 'file': 'The path to a yml/json file that contain all the script input parameters.', 'outputType': 'The type of output of script execution. available options are json (default) and csv.', 'outDir': 'The path to store output of script execution. The default is the current working directory.', 'logLevel': 'Used to categorize and prioritize log levels based on severity or importance. Its values can be INFO, DEBUG, WARNING, ERROR, or CRITICAL. The default value is INFO.', 'testId': 'Description for test to be executed.'}}

s3_check_public_access_readme_data= {'help': 'This automation helps to execute Tamnoon S3 automation to find which s3 buckets have public access.', 'cli_args': {'profile': 'Use the aws profile for setting up session during automation.', 'awsAccessKey': 'Use the aws access key for setting up session during automation. This must be accompanied by --awsSecret.', 'awsSecret': 'Use the aws secret key for setting up session during automation. This must be accompanied by --awsAccessKey.', 'awsSessionToken': 'Use the short term session token for setting up session during automation. This must be accompanied by --awsSecret and --awsAccessKey.', 'bucketNames': 'Comma separated list of S3 Buckets Name', 'file': 'The path to a yml/json file that contain all the script input parameters.', 'regions': "List of Regions. If not given then default value is 'all', i.e., remedy will evaluate all the S3 Buckets without checking its regions.", 'outputType': 'The type of output of script execution. available options are json (default) and csv.', 'outDir': 'The path to store output of script execution. The default is the current working directory.', 'logLevel': 'Used to categorize and prioritize log levels based on severity or importance. Its values can be INFO, DEBUG, WARNING, ERROR, or CRITICAL. The default value is INFO.', 'testId': 'Description for test to be executed.'}}

s3_enable_encryption_readme_data= {'help': 'This automation helps to execute Tamnoon S3 soft configuration automation to enable bucket encryption.', 'cli_args': {'profile': 'Use the aws profile for setting up session during automation.', 'awsAccessKey': 'Use the aws access key for setting up session during automation. This must be accompanied by --awsSecret.', 'awsSecret': 'Use the aws secret key for setting up session during automation. This must be accompanied by --awsAccessKey.', 'awsSessionToken': 'Use the short term session token for setting up session during automation. This must be accompanied by --awsSecret and --awsAccessKey.', 'bucketNames': 'Comma separated list of S3 Buckets Name', 'regions': "List of Regions. If not given then default value is 'all', i.e., remedy will configure all the S3 Buckets without checking its regions.", 'actionParams': '1. kms - The id of the kms key to use for encryption.If not delivered the bucket will be encrypted using s3 key.', 'revert': 'Boolean Value true/false used to revert the action.', 'file': 'The path to a yml/json file that contain all the script input parameters.', 'outputType': 'The type of output of script execution. available options are json (default) and csv.', 'outDir': 'The path to store output of script execution. The default is the current working directory.', 'logLevel': 'Used to categorize and prioritize log levels based on severity or importance. Its values can be INFO, DEBUG, WARNING, ERROR, or CRITICAL. The default value is INFO.', 'testId': 'Description for test to be executed.'}}

s3_enable_server_logging_readme_data= {'help': 'This automation helps to to execute Tamnoon S3 soft configuration automation to enable server logging.', 'cli_args': {'profile': 'Use the aws profile for setting up session during automation.', 'awsAccessKey': 'Use the aws access key for setting up session during automation. This must be accompanied by --awsSecret.', 'awsSecret': 'Use the aws secret key for setting up session during automation. This must be accompanied by --awsAccessKey.', 'awsSessionToken': 'Use the short term session token for setting up session during automation. This must be accompanied by --awsSecret and --awsAccessKey.', 'bucketNames': 'Comma separated list of S3 Buckets Name', 'regions': "List of Regions. If not given then default value is 'all', i.e., remedy will configure all the S3 Buckets without checking its regions.", 'actionParams': '1. target_bucket - The target bucket to save the logs to.', 'revert': 'Boolean Value true/false used to revert the action.', 'file': 'The path to a yml/json file that contain all the script input parameters.', 'outputType': 'The type of output of script execution. available options are json (default) and csv.', 'outDir': 'The path to store output of script execution. The default is the current working directory.', 'logLevel': 'Used to categorize and prioritize log levels based on severity or importance. Its values can be INFO, DEBUG, WARNING, ERROR, or CRITICAL. The default value is INFO.', 'testId': 'Description for test to be executed.'}}

s3_enable_versioning_readme_data= {'help': 'This automation helps to to execute Tamnoon S3 soft configuration automation to enable bucket versioning.', 'cli_args': {'profile': 'Use the aws profile for setting up session during automation.', 'awsAccessKey': 'Use the aws access key for setting up session during automation. This must be accompanied by --awsSecret.', 'awsSecret': 'Use the aws secret key for setting up session during automation. This must be accompanied by --awsAccessKey.', 'awsSessionToken': 'Use the short term session token for setting up session during automation. This must be accompanied by --awsSecret and --awsAccessKey.', 'bucketNames': 'Comma separated list of S3 Buckets Name', 'regions': "List of Regions. If not given then default value is 'all', i.e., remedy will configure all the S3 Buckets without checking its regions.", 'revert': 'Boolean Value true/false used to revert the action.', 'file': 'The path to a yml/json file that contain all the script input parameters.', 'outputType': 'The type of output of script execution. available options are json (default) and csv.', 'outDir': 'The path to store output of script execution. The default is the current working directory.', 'logLevel': 'Used to categorize and prioritize log levels based on severity or importance. Its values can be INFO, DEBUG, WARNING, ERROR, or CRITICAL. The default value is INFO.', 'testId': 'Description for test to be executed.'}}

s3_block_public_access_readme_data= {'help': 'This automation helps to execute Tamnoon S3 soft configuration automation to block public access.', 'cli_args': {'profile': 'Use the aws profile for setting up session during automation.', 'awsAccessKey': 'Use the aws access key for setting up session during automation. This must be accompanied by --awsSecret.', 'awsSecret': 'Use the aws secret key for setting up session during automation. This must be accompanied by --awsAccessKey.', 'awsSessionToken': 'Use the short term session token for setting up session during automation. This must be accompanied by --awsSecret and --awsAccessKey.', 'bucketNames': 'Comma separated list of S3 Buckets Name', 'regions': "List of Regions. If not given then default value is 'all', i.e., remedy will configure all the S3 Buckets without checking its regions.", 'actionParams': '1. BlockPublicAcls (boolean) -\n\n    Specifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and objects in this bucket. Setting this element to TRUE enables the block public access for S3 bucket\n    \n    Enabling this setting doesn’t affect existing policies or ACLs.\n2. IgnorePublicAcls (boolean) -\n\n    Specifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this bucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket and objects in this bucket. \n\n    Enabling this setting doesn’t affect the persistence of any existing ACLs and doesn’t prevent new public ACLs from being set.\n3. BlockPublicPolicy (boolean) -\n\n    Specifies whether Amazon S3 should block public bucket policies for this bucket. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n\n    Enabling this setting doesn’t affect existing bucket policies.\n4. RestrictPublicBuckets (boolean) -\n\n    Specifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this element to TRUE restricts access to this bucket to only Amazon Web Service principals and authorized users within this account if the bucket has a public policy.\n\n    Enabling this setting doesn’t affect previously stored bucket policies, except that public and cross-account access within any public bucket policy, including non-public delegation to specific accounts, is blocked.', 'file': 'The path to a yml/json file that contain all the script input parameters.', 'outputType': 'The type of output of script execution. available options are json (default) and csv.', 'outDir': 'The path to store output of script execution. The default is the current working directory.', 'logLevel': 'Used to categorize and prioritize log levels based on severity or importance. Its values can be INFO, DEBUG, WARNING, ERROR, or CRITICAL. The default value is INFO.', 'testId': 'Description for test to be executed.'}}

common_json_data= {'help': {'EC2Actions': {'snapshot': 'An EBS snapshot is a point-in-time, incremental backup of an Amazon Elastic Block Store (EBS) volume stored in Amazon S3, allowing restoration of the volume to its exact state at the time of the snapshot.', 'security-group': 'An AWS Security Group acts as a virtual firewall that controls inbound and outbound traffic to AWS resources within a Virtual Private Cloud (VPC) based on specified security rules.', 'vpc': 'An AWS Virtual Private Cloud (VPC) is a customizable network environment that allows users to launch AWS resources in a logically isolated, secure section of the AWS Cloud.', 'ec2': 'Amazon EC2 (Elastic Compute Cloud) is a web service that provides resizable compute capacity in the cloud, allowing users to run virtual servers to host applications and services.', 'subnet': "An AWS Subnet is a segment of a VPC's IP address range where you can place groups of isolated resources based on security and operational needs within a larger VPC network.", 'alb': 'An Application Load Balancer is an Elastic Load Balancing service provided by AWS that functions at the application layer, the seventh layer of the Open Systems Interconnection (OSI) model.'}, 'CloudFormation': {'describe-stack-resources': 'Determines whether the resource is part of a CloudFormation stack. If so, the results describe all resources deployed by the CloudFormation stack.'}, 'RDSActions': {'rds': 'Amazon Relational Database Service (Amazon RDS) is an easy-to-manage relational database service optimized for total cost of ownership. It is simple to set up, operate, and scale with demand. Amazon RDS automates the undifferentiated database management tasks, such as provisioning, configuring, backups, and patching'}, 'IAMActions': {'iam-user': 'An AWS Identity and Access Management (IAM) user is an entity that you create in AWS. The IAM user represents the human user or workload who uses the IAM user to interact with AWS. A user in AWS consists of a name and credentials.'}, 'S3Actions': {'s3': 'Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance.S3 is used to store and protect any amount of data for a range of use cases, such as data lakes, websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics.'}, 'LogsInvestigation': {'cloudtrail': 'AWS CloudTrail is an AWS service that helps you enable operational and risk auditing, governance, and compliance of your AWS account. Actions taken by a user, role, or an AWS service are recorded as events in CloudTrail. The recorded events are stored in S3 bucket and queried using athena.', 'events-history': 'The Event history provides a viewable, searchable, downloadable, and immutable record of the past 90 days of management events in an AWS Region'}}, 'usage': {'EC2Actions': 'python3 -m Automations.EC2Actions', 'CloudFormation': 'python3 -m Automations.CloudFormation', 'S3Actions': 'python3 -m Automations.S3Actions', 'IAMActions': 'python3 -m Automations.IAMActions', 'RDSActions': 'python3 -m Automations.RDSActions', 'EBS_Encryption': '', 'LogsInvestigation': 'python3 -m Automations.LogsInvestigation'}}
